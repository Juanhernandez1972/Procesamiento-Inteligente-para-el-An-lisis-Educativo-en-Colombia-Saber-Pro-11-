# üìä Procesamiento Inteligente para el An√°lisis Educativo en Colombia (Saber Pro-11)

Este proyecto corresponde a la aplicaci√≥n de distintos conocimientos adquiridos en la materia de **ETL (Extract, Transform, Load)** utilizando Python y sus librer√≠as orientadas al an√°lisis y procesamiento de datos. El objetivo principal es realizar la limpieza, transformaci√≥n y carga de un conjunto de datos relacionados con los resultados de las pruebas **Saber Pro ‚Äì 11** en Colombia.

---

## üéØ Objetivo

Aplicar un proceso ETL para preparar datos de los resultados de las pruebas Saber Pro-11 con el fin de dejarlos listos para an√°lisis posteriores. Esto incluye:

- Detecci√≥n y correcci√≥n de valores nulos  
- Transformaci√≥n de tipos de datos  
- Creaci√≥n de nuevas variables  
- Exportaci√≥n del resultado limpio

---

### üë®‚Äçüíª Tecnolog√≠as y Herramientas

<br />

[![Python](https://img.shields.io/badge/Python-black?style=for-the-badge&logo=python)](https://www.python.org/)  
[![Pandas](https://img.shields.io/badge/Pandas-purple?style=for-the-badge&logo=pandas)](https://pandas.pydata.org/)  
[![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy)](https://numpy.org/)  
[![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=for-the-badge&logo=matplotlib)](https://matplotlib.org/)  
[![Seaborn](https://img.shields.io/badge/Seaborn-7cb9e8?style=for-the-badge&logo=seaborn)](https://seaborn.pydata.org/)  
![Datetime](https://img.shields.io/badge/Datetime-333333?style=for-the-badge)  
[![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter)](https://jupyter.org/)  
[![Google Colab](https://img.shields.io/badge/Google%20Colab-F9AB00?style=for-the-badge&logo=googlecolab)](https://colab.research.google.com/)

---

## üîç Estructura del proceso ETL

### 1. **Extracci√≥n de datos**
Se carga un archivo `.TXT` con los resultados de las pruebas Saber Pro-11 (por ejemplo: `SB11_20232.TXT`), que se convierte a un DataFrame.

### 2. **Transformaci√≥n de datos**
- Limpieza de columnas y nombres  
- Conversi√≥n de fechas  
- Manejo de valores nulos  
- Creaci√≥n de nuevas columnas  
- Validaciones y estandarizaci√≥n de formatos  
- An√°lisis exploratorio (opcional)

### 3. **Carga de datos**
- Exportaci√≥n del dataset limpio a un archivo `.csv`

---

## ‚öôÔ∏è ETL Pipeline: Descripci√≥n General

Este pipeline automatiza el proceso **ETL** (Extracci√≥n, Transformaci√≥n y Carga), permitiendo una gesti√≥n eficiente de los datos desde su origen hasta su almacenamiento final en un formato listo para an√°lisis.

La funci√≥n `run_etl()` act√∫a como el **orquestador principal del flujo de trabajo**.

---

## üîÅ Funcionalidades del Pipeline

1. **Creaci√≥n de estructura de carpetas**  
   - `create_project_structure()` genera carpetas para datos crudos, transformados, logs y otros archivos auxiliares.

2. **Configuraci√≥n del sistema de logging**  
   - `setup_logging()` permite el monitoreo del pipeline y la detecci√≥n de errores.

3. **Extracci√≥n de datos**  
   - `extract_data()` accede al archivo fuente y lo convierte a un DataFrame.

4. **Transformaci√≥n de los datos**  
   - `transform_data(df_raw)` limpia y estandariza los datos para su an√°lisis.

5. **Carga de datos transformados**  
   - `load_data()` exporta el resultado final a `.csv` en la carpeta definida.

6. **(Opcional) An√°lisis exploratorio**  
   - Se puede a√±adir an√°lisis exploratorio como parte del pipeline o en una etapa posterior.

---

## üß™ Ejecuci√≥n del Pipeline

Para correr todo el flujo ETL, simplemente ejecuta:

```python
run_etl()
```

---

## üë• Autores

- Juan Felipe Hern√°ndez  
- Manuel Enrique Luna Alegr√≠a  
- Dallys Nicol Sinisterra Guti√©rrez
